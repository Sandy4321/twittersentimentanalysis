{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read and Clean the tweets database \n",
    "\n",
    "\n",
    "I exported the tweets database called \"rockets\" from mongodb as a .json file (which can be done directly from the terminal window). Here, I read the rockets.json file and save it in a pandas dataframe. I have 105,783 tweets! Using BeautifulSoup and regular expressions, I remove html and all non-letter characters from the text. Using NLTK's stopwords  corpus, I remove all stopwords. I further clean the text by removing 'http', 'https', '@', and 'rt' (symbolizing retweets) from the text. Finally, I save my clean text as a separate column in the dataframe and export the whole file in a .csv format for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules \n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the json file and put it in a df\n",
    "\n",
    "path = 'rockets.json'\n",
    "record = [json.loads(line) for line in open(path)]\n",
    "rockets = DataFrame(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105783, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rockets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Getting ready for Game 2 Rockets vs. Warriors ...\n",
       "1     RT @iamC_Mart: If Lil B curse James Harden, it...\n",
       "2     Tonight's free pick: \\n\\nHouston Rockets +10.5...\n",
       "3                                    Let‚Äôs go Rockets!!\n",
       "4                             rockets boutta win game 2\n",
       "5     RT @ComplexMag: Rockets fans are begging Lil B...\n",
       "6     RT @lildelvin_: Rockets can't take this L today üò∑\n",
       "7     RT @SportsCenter: Rockets and Warriors meet fo...\n",
       "8                 Nah cuh chill https://t.co/41qQRLNevT\n",
       "9     RT @rjthamacrj: The Rockets are about to play ...\n",
       "10    RT @SportsCenter: Draymond Green enters arena ...\n",
       "11                                warriors &gt; rockets\n",
       "12    RT @_RJack1_: About to lock-in on this Warrior...\n",
       "13    RT @SportsCenter: Rockets and Warriors meet fo...\n",
       "14    RT @ESPNStatsInfo: Rockets are +12 with Howard...\n",
       "15    RT @SBNationNBA: Dwight Howard is in for Game ...\n",
       "16    Houston Rockets vs. Golden State Warriors: Liv...\n",
       "17    Houston Rockets vs. Golden State Warriors: Liv...\n",
       "18    Top #NBA Pick 1:  Houston Rockets vs Golden St...\n",
       "19    Top #NBA Pick 2:  Houston Rockets vs Golden St...\n",
       "20    Top #NBA Pick 3:  Houston Rockets vs Golden St...\n",
       "21                  Dwight Howard will play for Rockets\n",
       "22    Top #NBA Pick 5: 1H Houston Rockets vs1H Golde...\n",
       "23    RT @LetsGoWarriors: Chef scoopin'! üèÄ #StephCur...\n",
       "24      @HoustonRockets Let's Go Rockets! We can do it!\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rockets ['text'][0:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Clean and preprocess data \n",
    "\n",
    "Kaggle has an excellent [tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) that helped me get started "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_to_words( raw_text):\n",
    "    # Function to convert a raw tweet to a string of words\n",
    "    # The input is a single string (a raw tweet), and \n",
    "    # the output is a single string (a preprocessed tweet)\n",
    "    \n",
    "#1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_text).get_text() \n",
    "\n",
    "# 2. Remove non-letters       \n",
    "    letters_only = re.sub(\"[^a-zA-Z]+\", \" \", review_text) \n",
    "    \n",
    "# 3. Convert to lower case and split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    \n",
    "# 4. In Python, searching a set is much faster than searching a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "\n",
    "# 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops \n",
    "                            and 'http' not in w\n",
    "                            and 'https' not in w\n",
    "                            and \"'\" not in w  \n",
    "                            and not w.startswith('@')\n",
    "                            and w != 'rt']   \n",
    "    \n",
    "# 6. Join the words back into one string separated by space and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting ready game rockets vs warriors warriors spashbros nba basketball besureinc co glrexsuchm\n"
     ]
    }
   ],
   "source": [
    "clean_tweet = tweet_to_words( rockets['text'][0] )\n",
    "print (clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/UwRijDGHKW\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/oDSwpHp9ji\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"http://t.co/itiyukzdHp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"http://t.co/UXqac099x2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"http://t.co/CPay7ynL63\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/5c0Dx8Y39X\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/kUD1dwSCZe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/2yYBhFd2CY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/I3ptVuiokv\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/o6yE3bOvly\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/CiNXQWSIkE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "/Users/Deepna/anaconda/lib/python3.4/site-packages/bs4/__init__.py:189: UserWarning: \"https://t.co/yvRVU7xKJ2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "# Get the number of tweets based on the dataframe column size\n",
    "num_tweets = rockets['text'].size\n",
    "\n",
    "# Initialize an empty list to hold the clean tweets\n",
    "clean_tweets = []\n",
    "\n",
    "# Loop over each tweet; create an index i that goes from 0 to the length of the tweet list\n",
    "for i in range( 0, num_tweets ):\n",
    "    # Call the function for each one, and add the result to the list of clean tweets\n",
    "    clean_tweets.append(tweet_to_words( rockets['text'][i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['getting ready game rockets vs warriors warriors spashbros nba basketball besureinc co glrexsuchm',\n",
       " 'iamc mart lil b curse james harden curtains rockets',\n",
       " 'tonight free pick houston rockets u',\n",
       " 'let go rockets',\n",
       " 'rockets boutta win game']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rockets['CleanText'] = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> {'$oid': '555e7c38311e9d08bb45c086'}</td>\n",
       "      <td> {'$date': 1432255544000}</td>\n",
       "      <td> None</td>\n",
       "      <td>           Instagram</td>\n",
       "      <td> Getting ready for Game 2 Rockets vs. Warriors ...</td>\n",
       "      <td> getting ready game rockets vs warriors warrior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> {'$oid': '555e7c3b311e9d08bb45c087'}</td>\n",
       "      <td> {'$date': 1432255545000}</td>\n",
       "      <td> None</td>\n",
       "      <td> Twitter for Android</td>\n",
       "      <td> RT @iamC_Mart: If Lil B curse James Harden, it...</td>\n",
       "      <td> iamc mart lil b curse james harden curtains ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> {'$oid': '555e7c3b311e9d08bb45c088'}</td>\n",
       "      <td> {'$date': 1432255546000}</td>\n",
       "      <td> None</td>\n",
       "      <td>  Twitter for iPhone</td>\n",
       "      <td> Tonight's free pick: \\n\\nHouston Rockets +10.5...</td>\n",
       "      <td>               tonight free pick houston rockets u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> {'$oid': '555e7c3b311e9d08bb45c089'}</td>\n",
       "      <td> {'$date': 1432255546000}</td>\n",
       "      <td> None</td>\n",
       "      <td>    Tweetbot for iŒüS</td>\n",
       "      <td>                                Let‚Äôs go Rockets!!</td>\n",
       "      <td>                                    let go rockets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> {'$oid': '555e7c3b311e9d08bb45c08a'}</td>\n",
       "      <td> {'$date': 1432255546000}</td>\n",
       "      <td> None</td>\n",
       "      <td>  Twitter for iPhone</td>\n",
       "      <td>                         rockets boutta win game 2</td>\n",
       "      <td>                           rockets boutta win game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id                created_at   geo  \\\n",
       "0  {'$oid': '555e7c38311e9d08bb45c086'}  {'$date': 1432255544000}  None   \n",
       "1  {'$oid': '555e7c3b311e9d08bb45c087'}  {'$date': 1432255545000}  None   \n",
       "2  {'$oid': '555e7c3b311e9d08bb45c088'}  {'$date': 1432255546000}  None   \n",
       "3  {'$oid': '555e7c3b311e9d08bb45c089'}  {'$date': 1432255546000}  None   \n",
       "4  {'$oid': '555e7c3b311e9d08bb45c08a'}  {'$date': 1432255546000}  None   \n",
       "\n",
       "                source                                               text  \\\n",
       "0            Instagram  Getting ready for Game 2 Rockets vs. Warriors ...   \n",
       "1  Twitter for Android  RT @iamC_Mart: If Lil B curse James Harden, it...   \n",
       "2   Twitter for iPhone  Tonight's free pick: \\n\\nHouston Rockets +10.5...   \n",
       "3     Tweetbot for iŒüS                                 Let‚Äôs go Rockets!!   \n",
       "4   Twitter for iPhone                          rockets boutta win game 2   \n",
       "\n",
       "                                           CleanText  \n",
       "0  getting ready game rockets vs warriors warrior...  \n",
       "1  iamc mart lil b curse james harden curtains ro...  \n",
       "2                tonight free pick houston rockets u  \n",
       "3                                     let go rockets  \n",
       "4                            rockets boutta win game  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rockets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_rockets = rockets.drop(['_id','created_at','geo','source','text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> getting ready game rockets vs warriors warrior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> iamc mart lil b curse james harden curtains ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>               tonight free pick houston rockets u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>                                    let go rockets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>                           rockets boutta win game</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           CleanText\n",
       "0  getting ready game rockets vs warriors warrior...\n",
       "1  iamc mart lil b curse james harden curtains ro...\n",
       "2                tonight free pick houston rockets u\n",
       "3                                     let go rockets\n",
       "4                            rockets boutta win game"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_rockets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_rockets.to_csv('rockets_cleantext.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
